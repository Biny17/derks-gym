{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:30:31.145326: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from src import environments\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import tensorflow as tf\n",
    "from gym_derk.envs import DerkEnv\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from src.environments import EnvPerso, EnvTensorOne\n",
    "import tf_agents\n",
    "import reverb\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "import reverb\n",
    "from tf_agents.drivers import py_driver\n",
    "\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "import tensorflow as tf\n",
    "from tf_agents.agents.ppo import ppo_agent\n",
    "from tf_agents.networks import actor_distribution_network, value_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000 \n",
    "\n",
    "initial_collect_steps = 100 \n",
    "collect_steps_per_iteration =   1\n",
    "replay_buffer_max_length = 1000\n",
    "\n",
    "batch_size = 64  \n",
    "learning_rate = 1e-3  \n",
    "log_interval = 200 \n",
    "\n",
    "num_eval_episodes = 10 \n",
    "eval_interval = 1000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = EnvTensorOne()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network for the agent.\n",
    "actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "    env.observation_tensor_spec(),\n",
    "    env.action_tensor_spec())\n",
    "\n",
    "value_net = value_network.ValueNetwork(\n",
    "    env.observation_tensor_spec())\n",
    "\n",
    "# Define the keras optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# Define the train step counter.\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "# Create the PPO agent.\n",
    "agent = ppo_agent.PPOAgent(\n",
    "    env.time_step_spec(),\n",
    "    env.action_tensor_spec(),\n",
    "    optimizer,\n",
    "    actor_net=actor_net,\n",
    "    value_net=value_net,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "# Initialize the agent.\n",
    "agent.initialize()\n",
    "\n",
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.agents.ppo.ppo_policy.PPOPolicy at 0x7f619066a290>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(env.time_step_spec(),\n",
    "                                                env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugReverbAddTrajectoryObserver(reverb_utils.ReverbAddTrajectoryObserver):\n",
    "    def __call__(self, trajectory):\n",
    "        print(trajectory)\n",
    "        super().__call__(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/tfrecord_checkpointer.cc:162]  Initializing TFRecordCheckpointer in /tmp/tmpz_mfac_r.\n",
      "[reverb/cc/platform/tfrecord_checkpointer.cc:567] Loading latest checkpoint from /tmp/tmpz_mfac_r\n",
      "[reverb/cc/platform/default/server.cc:71] Started replay server on port 46599\n"
     ]
    }
   ],
   "source": [
    "table_name = 'test_table'\n",
    "replay_buffer_signature = tensor_spec.from_spec(\n",
    "      agent.collect_data_spec)\n",
    "replay_buffer_signature = tensor_spec.from_spec(\n",
    "      agent.collect_data_spec)\n",
    "\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=replay_buffer_max_length,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "    signature=replay_buffer_signature)\n",
    "\n",
    "reverb_server = reverb.Server([table])\n",
    "\n",
    "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    local_server=reverb_server)\n",
    "\n",
    "rb_observer = DebugReverbAddTrajectoryObserver(\n",
    "  replay_buffer.py_client,\n",
    "  table_name,\n",
    "  sequence_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_TupleWrapper(Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(15,), dtype=tf.float32, name='action', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(64,), dtype=tf.float32, name='observation', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'policy_info': DictWrapper({'dist_params': DictWrapper({'loc': TensorSpec(shape=(15,), dtype=tf.float32, name='NormalProjectionNetwork_loc'), 'scale': TensorSpec(shape=(15,), dtype=tf.float32, name='NormalProjectionNetwork_scale')})}),\n",
       " 'reward': BoundedTensorSpec(shape=(), dtype=tf.float32, name='reward', minimum=array(0., dtype=float32), maximum=array(inf, dtype=float32)),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')}))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.21042061, -0.30629253,  0.01914287,  0.24728942,  0.33934212,\n",
      "        0.2127502 ,  0.        ,  0.        ,  0.5569837 ,  0.75553226,\n",
      "        0.8224182 ,  0.8092327 ,  0.1810453 ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.24078695, -0.8728948 ,  0.17336386,\n",
      "       -0.16567287,  0.2675242 , -0.39621603,  1.        , -0.02919272,\n",
      "        0.79562455, -0.09462335,  0.6693634 , -0.03331383,  0.6873951 ,\n",
      "        0.01854582,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.11146335,  0.11146335,  0.62728584, -0.03068253, -0.13041624,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.15461826,  0.02335691, -0.89934874,  0.11244106,  0.        ,\n",
      "        0.3741889 ,  0.0357275 ,  0.24324703,  0.20528626,  0.        ,\n",
      "        0.05090475,  0.6015129 ,  0.        ,  0.7191386 ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.24025877, -0.8728948 ,  0.17336386,\n",
      "       -0.16567287,  0.2675242 , -0.39621603,  1.        , -0.02919272,\n",
      "        0.79562455, -0.09462335,  0.6693634 , -0.03331383,  0.6873951 ,\n",
      "        0.01854582,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.5545997 , -0.03068253, -0.13041624,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.5509262 , -0.3792534 , -0.7490952 ,  0.53066087,  0.        ,\n",
      "        0.4473765 ,  0.18468165,  0.7172818 ,  0.84429145,  0.18252015,\n",
      "        0.        ,  0.25860167,  0.        ,  0.6732557 ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.25003466, -0.75965804,  0.18868445,\n",
      "       -0.03910659,  0.26112863, -0.25568   ,  0.9991942 ,  0.0933302 ,\n",
      "        0.75569504,  0.02378074,  0.62329715,  0.09079689,  0.6341842 ,\n",
      "        0.13484827,  1.        ,  0.301552  ,  0.17876291,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02983436, -0.12654516,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.03973246, -0.8270116 , -0.88166714,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.50259924,  0.        ,\n",
      "        0.702574  ,  0.        ,  0.27104974,  0.01453257,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.256139  , -0.77553904,  0.1951984 ,\n",
      "       -0.03180777,  0.25431517, -0.26605004,  0.9912705 ,  0.08513337,\n",
      "        0.78769463,  0.01537483,  0.56582934,  0.08304808,  0.6118695 ,\n",
      "        0.11726277,  1.        , -0.9165417 ,  0.99999917,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02885178, -0.12399474,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.6018219 , -0.67071533,  0.47592807,  0.        ,  0.        ,\n",
      "        0.15441799,  0.794827  ,  0.        ,  0.10236049,  0.        ,\n",
      "        0.        ,  0.7350924 ,  0.21963191,  0.85225964,  0.26240325],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.2737416 , -0.6587271 ,  0.16992377,\n",
      "        0.12532683,  0.2389616 , -0.08762927,  0.9661617 ,  0.2348328 ,\n",
      "        0.7170015 ,  0.16883616,  0.504485  ,  0.23807284,  0.5936582 ,\n",
      "        0.2781862 ,  1.        , -0.79807   ,  0.9935616 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02330831, -0.11608782,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.59340787, 0.77540207, 0.72367525, 0.11997128, 0.72751474,\n",
      "       0.04388261, 0.53475976, 0.10740018, 0.        , 0.10399437,\n",
      "       0.        , 0.        , 0.39478612, 0.        , 0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.2738695 , -0.3404051 ,  0.17111196,\n",
      "        0.438104  ,  0.22528346,  0.19538796,  0.96671563,  0.5500891 ,\n",
      "        0.6902282 ,  0.49612522,  0.4573985 ,  0.53970975,  0.60239816,\n",
      "        0.6014175 ,  1.        , -0.868452  ,  0.41272622,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02396891, -0.11622313,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.7461231 , -0.80114746,  0.68406963,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.18513131,  0.        ,  0.        ,\n",
      "        0.7117882 ,  0.35772347,  0.9650786 ,  0.        ,  0.10911226],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.24922739, -0.1075304 ,  0.18162805,\n",
      "        0.7475124 ,  0.22719544,  0.54582596,  0.9849415 ,  0.81452024,\n",
      "        0.7041225 ,  0.76507795,  0.45815793,  0.7988733 ,  0.64291227,\n",
      "        0.8799167 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.79824275,  0.        , -0.01594654, -0.12277582,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.67516685, -0.6308558 ,  0.6459756 ,  0.        ,  0.        ,\n",
      "        0.92191243,  0.        ,  0.        ,  0.46539903,  0.8179295 ,\n",
      "        0.        ,  0.8318486 ,  0.14292002,  0.7479603 ,  0.83543825],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.23068018, -0.4360178 ,  0.19160174,\n",
      "        0.50064874,  0.22566205,  0.3112056 ,  0.9989936 ,  0.5270707 ,\n",
      "        0.71401435,  0.48188406,  0.47566307,  0.5056811 ,  0.6602706 ,\n",
      "        0.5944535 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00713113, -0.127749  ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.41248274,  0.5945957 , -0.3442726 ,  0.5734272 ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.49135375,  0.89355946,\n",
      "        0.50903726,  0.        ,  0.16700578,  0.55298257,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.23991711, -0.66584444,  0.18376313,\n",
      "        0.41743302,  0.18979308,  0.19446608,  0.9902188 ,  0.37767866,\n",
      "        0.6989675 ,  0.3380389 ,  0.5088452 ,  0.36098695,  0.65528566,\n",
      "        0.45242047,  1.        ,  0.92695636,  0.27562156,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00867838, -0.12480103,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.12605643, 0.97190905, 0.26091027, 0.58836484, 0.        ,\n",
      "       0.5156467 , 0.8549762 , 0.        , 0.00254822, 0.        ,\n",
      "       0.42465448, 0.89883256, 0.7019913 , 0.14239025, 0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.25571653, -0.845917  ,  0.17361315,\n",
      "        0.2897959 ,  0.1566476 ,  0.10436092,  0.9770448 ,  0.22180176,\n",
      "        0.6838173 ,  0.18365066,  0.523406  ,  0.20710345,  0.6465357 ,\n",
      "        0.3006065 ,  1.        ,  0.7654861 ,  0.25439268,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01414156, -0.12023783,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.98775816, 0.42395234, 0.43049884, 0.        , 0.        ,\n",
      "       0.        , 0.22539139, 0.        , 0.        , 0.40774155,\n",
      "       0.78223586, 0.7861631 , 0.2901125 , 0.3629675 , 0.36044288],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.27703342,  0.92491025,  0.15515772,\n",
      "        0.08421308,  0.12420622, -0.01174155,  0.95646745, -0.00325204,\n",
      "        0.6626168 , -0.04166852,  0.5297647 , -0.01487414,  0.62800866,\n",
      "        0.07915924,  1.        ,  0.5384125 ,  0.24889737,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01591969, -0.11332244,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.41873336, -0.08391643, -0.22850776,  0.        ,  0.3766489 ,\n",
      "        0.62307143,  0.35892892,  0.        ,  0.        ,  0.        ,\n",
      "        0.01951075,  0.        ,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.29260004,  0.7460047 ,  0.13660465,\n",
      "       -0.10991136,  0.1279231 , -0.18762176,  0.93908906, -0.1957631 ,\n",
      "        0.646191  , -0.23622152,  0.5379632 , -0.20815852,  0.59921384,\n",
      "       -0.11012685,  1.        ,  0.3481261 ,  0.26191336,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01342806, -0.1076692 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.6066768 ,  0.20121479, -0.46562147,  0.9417672 ,  0.45146728,\n",
      "        0.        ,  0.        ,  0.62374187,  0.        ,  0.        ,\n",
      "        0.        ,  0.9500382 ,  0.8991182 ,  0.21228743,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.33540642,  0.8495878 ,  0.08576538,\n",
      "       -0.08018372,  0.13529679, -0.18129686,  0.8927638 , -0.1323587 ,\n",
      "        0.6037763 , -0.18006666,  0.4903458 , -0.1532074 ,  0.5272434 ,\n",
      "       -0.04233564,  1.        ,  0.4203241 ,  0.31027907,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00456473, -0.0925596 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.36850834, 0.7532363 , 0.3914528 , 0.        , 0.        ,\n",
      "       0.6749985 , 0.        , 0.        , 0.02606797, 0.31117702,\n",
      "       0.39686775, 0.3314097 , 0.581651  , 0.814342  , 0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.3152153 ,  0.8724926 ,  0.10775137,\n",
      "       -0.03533268,  0.15784177, -0.12344561,  0.91368294, -0.0975617 ,\n",
      "        0.6233645 , -0.14244542,  0.5152089 , -0.11285009,  0.5085599 ,\n",
      "       -0.0037001 ,  1.        ,  0.45239598,  0.29364213,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00727219, -0.09944564,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.42435694, 0.11503148, 0.75158525, 0.13621974, 0.9027953 ,\n",
      "       0.        , 0.        , 0.33971834, 0.        , 0.43061996,\n",
      "       0.88198066, 0.9420359 , 0.        , 0.        , 0.4776194 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.34322405,  0.8109865 ,  0.07685672,\n",
      "       -0.14492443,  0.17423922, -0.17897914,  0.88463753, -0.17941889,\n",
      "        0.5966882 , -0.22881138,  0.4908313 , -0.22152525,  0.5076383 ,\n",
      "       -0.09919677,  1.        ,  0.3755215 ,  0.32199427,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00246138, -0.08988923,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.85259986,  0.19088268, -0.52725077,  0.04494715,  0.4590385 ,\n",
      "        0.79043126,  0.4915049 ,  0.        ,  0.14677668,  0.8967736 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.3625102 ,  0.22400212],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.36998767,  0.80233496,  0.05056969,\n",
      "       -0.27133253,  0.17471533, -0.23662981,  0.8579303 , -0.21196187,\n",
      "        0.57343155, -0.26697898,  0.4735989 , -0.26966903,  0.47966465,\n",
      "       -0.16130938,  1.        ,  0.34997088,  0.3592362 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00383621, -0.08101535,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.1039288 , 0.22576737, 0.18725705, 0.        , 0.        ,\n",
      "       0.345119  , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.48970604],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.40493262, -0.91671336,  0.03333332,\n",
      "       -0.2871784 ,  0.18803796, -0.0246903 ,  0.8244078 ,  0.04679935,\n",
      "        0.5387867 , -0.01144679,  0.44257367, -0.0210056 ,  0.44337958,\n",
      "        0.09485789,  1.        ,  0.76773083,  0.7689168 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01028561, -0.06972808,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.2783494 , -0.87230015,  0.87241936,  0.27772284,  0.53148603,\n",
      "        0.34090066,  0.        ,  0.11701751,  0.91836405,  0.01869774,\n",
      "        0.        ,  0.        ,  0.        ,  0.68520594,  0.9656873 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.44889742, -0.98956764,  0.04354276,\n",
      "       -0.7407106 ,  0.11631433, -0.09497678,  0.7806666 , -0.02818386,\n",
      "        0.44563478, -0.08797693,  0.35578495, -0.10755225,  0.40656683,\n",
      "        0.04906755,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01143226, -0.055159  ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.11503625, -0.76146984, -0.6678996 ,  0.        ,  0.02597404,\n",
      "        0.5110824 ,  0.        ,  0.        ,  0.43203044,  0.99479246,\n",
      "        0.        ,  0.9908345 ,  0.42874885,  0.7152951 ,  0.24257183],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.46321195,  0.9377626 ,  0.0557371 ,\n",
      "       -0.865058  ,  0.12133132, -0.19174577,  0.7666724 , -0.10364474,\n",
      "        0.38704675, -0.16639999,  0.2937146 , -0.20026822,  0.39249417,\n",
      "       -0.03006782,  1.        ,  0.7815444 ,  0.8299695 ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01241621, -0.05046561,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.8527472 , -0.06940937,  0.2771001 ,  0.02589583,  0.32750726,\n",
      "        0.        ,  0.        ,  0.        ,  0.7182298 ,  0.1173048 ,\n",
      "        0.        ,  0.        ,  0.7951181 ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.50756586,  0.9713395 ,  0.09698103,\n",
      "       -0.9081914 ,  0.08402212, -0.24730492,  0.72327095, -0.0771024 ,\n",
      "        0.31111613, -0.16889316,  0.2995226 , -0.20158386,  0.31693965,\n",
      "        0.0062486 ,  1.        , -0.99620324,  0.9999703 ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.0150066 , -0.03589964,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.10915136, 0.83233833, 0.85067177, 0.        , 0.        ,\n",
      "       0.6285696 , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.7030947 , 0.        , 0.59944224, 0.        , 0.58984137],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5129634 , -0.73930234,  0.10118995,\n",
      "       -0.630774  ,  0.06938709, -0.066385  ,  0.7175687 ,  0.21447639,\n",
      "        0.29650742,  0.10118143,  0.2634369 ,  0.08163241,  0.27619913,\n",
      "        0.29805624,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01436177, -0.03404388,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.99333954,  0.25219178, -0.87947655,  0.        ,  0.13606644,\n",
      "        0.6648748 ,  0.        ,  0.        ,  0.7770164 ,  0.        ,\n",
      "        0.40260768,  0.        ,  0.        ,  0.38783813,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4847991 , -0.690008  ,  0.09503671,\n",
      "       -0.45665413,  0.13311669,  0.09113548,  0.7522993 ,  0.22828148,\n",
      "        0.33787596,  0.12925959,  0.25559774,  0.08632285,  0.3031319 ,\n",
      "        0.284735  ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02497172, -0.04474634,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.1149354 ,  0.8786011 ,  0.15054083,  0.        ,  0.        ,\n",
      "        0.        ,  0.45515585,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.9388807 ,  0.55599165,  0.31818056,  0.3092487 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.52657455,  0.9950714 ,  0.12225409,\n",
      "       -0.86617935,  0.08882491, -0.2974188 ,  0.7082191 , -0.07559748,\n",
      "        0.26625714, -0.17245267,  0.1897964 , -0.2688545 ,  0.25533202,\n",
      "       -0.0079865 ,  1.        , -0.93796307,  0.9758931 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02214557, -0.03032815,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.16818571, -0.08180952, -0.02543664,  0.        ,  0.1723175 ,\n",
      "        0.1222074 ,  0.        ,  0.52300215,  0.72938013,  0.6324568 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.6661477 ,  0.77950764],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4749103 ,  0.89219946,  0.07230838,\n",
      "       -0.9046772 ,  0.16230561, -0.22355296,  0.75691384, -0.1631369 ,\n",
      "        0.2616291 , -0.25290513,  0.20812824, -0.31632876,  0.27805895,\n",
      "       -0.10248687,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01675591, -0.0469713 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.07178879, -0.7713103 , -0.3777051 ,  0.6589875 ,  0.        ,\n",
      "        0.47981477,  0.        ,  0.16845417,  0.        ,  0.37702537,\n",
      "        0.        ,  0.        ,  0.24830246,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.47694805,  0.6658835 ,  0.07505725,\n",
      "        0.86895674,  0.15796238, -0.4568963 ,  0.7552329 , -0.39157894,\n",
      "        0.2569824 , -0.4966133 ,  0.22531822, -0.5399652 ,  0.22411679,\n",
      "       -0.3412441 ,  1.        ,  0.6306316 ,  0.9975649 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01744252, -0.04636532,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.9392414 ,  0.36661172, -0.855479  ,  0.27124572,  0.91145706,\n",
      "        0.        ,  0.7202451 ,  0.97459626,  0.20591736,  0.96189594,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.6693716 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4721333 ,  0.69203377,  0.06672803,\n",
      "        0.8852779 ,  0.19779126, -0.4495845 ,  0.7587307 , -0.35686955,\n",
      "        0.22988018, -0.40180063,  0.20464627, -0.5013252 ,  0.22218274,\n",
      "       -0.3017015 ,  1.        ,  0.7939633 ,  0.9551577 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01478675, -0.04769924,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.95189404,  0.649714  ,  0.39738894,  0.        ,  0.34949088,\n",
      "        0.21359968,  0.        ,  0.        ,  0.24966788,  0.        ,\n",
      "        0.        ,  0.        ,  0.37723947,  0.44193864,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4754611 ,  0.9877245 ,  0.07037882,\n",
      "       -0.82276165,  0.17399809, -0.08723407,  0.7556875 , -0.06315591,\n",
      "        0.21204402, -0.06053107,  0.2084508 , -0.21221496,  0.19817372,\n",
      "       -0.01253833,  1.        ,  0.40682462, -0.10218835,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01541832, -0.04664966,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.5562322 , -0.54256964, -0.47724152,  0.        ,  0.        ,\n",
      "        0.67851377,  0.        ,  0.45626783,  0.25837564,  0.12778568,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.42813537,  0.83722043,  0.06373677,\n",
      "       -0.5691014 ,  0.22152129, -0.21268803,  0.8007727 , -0.19469325,\n",
      "        0.2521327 , -0.22977978,  0.21129479, -0.263311  ,  0.223344  ,\n",
      "       -0.12382659,  1.        ,  0.17857927, -0.28405407,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00924343, -0.06192058,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.02247095, -0.5455282 ,  0.8252237 ,  0.        ,  0.        ,\n",
      "        0.48870134,  0.32529926,  0.        ,  0.        ,  0.        ,\n",
      "        0.3320496 ,  0.        ,  0.13197398,  0.54991436,  0.8896277 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.41996887,  0.8359883 ,  0.05196101,\n",
      "       -0.53172046,  0.22874843, -0.20217381,  0.8085012 , -0.19033775,\n",
      "        0.2595348 , -0.21892188,  0.19628496, -0.22897469,  0.23503628,\n",
      "       -0.11973143,  1.        ,  0.6376108 ,  0.913362  ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00755504, -0.06453881,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.5985563 , -0.9024594 , -0.86665154,  0.11458492,  0.        ,\n",
      "        0.        ,  0.        ,  0.028862  ,  0.10914278,  0.57852054,\n",
      "        0.8938241 ,  0.80940866,  0.28043222,  0.33825397,  0.73936534],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.39125428, -0.9602965 ,  0.07445423,\n",
      "       -0.21409787,  0.28102085,  0.04563743,  0.8368799 ,  0.01947021,\n",
      "        0.2900905 ,  0.01093976,  0.18433127, -0.00375357,  0.28433612,\n",
      "        0.08395281,  1.        , -0.9782057 ,  0.9967797 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00560263, -0.0740023 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.87621164,  0.21219015, -0.53923583,  0.        ,  0.        ,\n",
      "        0.20774055,  0.3357203 ,  0.        ,  0.        ,  0.        ,\n",
      "        0.39893985,  0.20024848,  0.        ,  0.16227627,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.43465775,  0.9618218 ,  0.07137467,\n",
      "       -0.53648865,  0.22744983, -0.04062251,  0.79381603, -0.06474427,\n",
      "        0.22929016, -0.0865355 ,  0.09243774, -0.09576938,  0.20769359,\n",
      "        0.00595372,  1.        ,  0.9945913 ,  0.9993627 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00775161, -0.05965969,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.9340441 ,  0.91269135,  0.00253224,  0.95537233,  0.        ,\n",
      "        0.        ,  0.        ,  0.8727925 ,  0.        ,  0.8557117 ,\n",
      "        0.00693059,  0.        ,  0.        ,  0.2342999 ,  0.48546886],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.46165183, -0.70334625,  0.10098328,\n",
      "       -0.40200886,  0.20646097,  0.33254778,  0.7659937 ,  0.28496176,\n",
      "        0.20082262,  0.21881472,  0.0393315 ,  0.24036285,  0.16442986,\n",
      "        0.38195422,  1.        , -0.71064585,  0.99990463,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00350213, -0.05052006,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.30623126, 0.80276394, 0.6778867 , 0.        , 0.        ,\n",
      "       0.        , 0.21948242, 0.6693082 , 0.48191667, 0.9145074 ,\n",
      "       0.        , 0.7532389 , 0.        , 0.        , 0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.48327598, -0.8092367 ,  0.09629893,\n",
      "       -0.6168337 ,  0.19242403,  0.27767032,  0.74535084,  0.21968009,\n",
      "        0.16020426,  0.25655532,  0.03298382,  0.5090422 ,  0.13691688,\n",
      "        0.38825482,  1.        , -0.79168266,  0.9993632 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00880775, -0.0435386 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.00928688,  0.7449305 , -0.94698334,  0.        ,  0.        ,\n",
      "        0.14816046,  0.        ,  0.        ,  0.        ,  0.41495395,\n",
      "        0.        ,  0.10172868,  0.        ,  0.7091577 ,  0.15829825],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.43624032,  0.84207684,  0.10901631,\n",
      "       -0.88958144,  0.22474627, -0.03692548,  0.79234594, -0.12983973,\n",
      "        0.21022777, -0.16751483,  0.07892716, -0.03695155,  0.13543397,\n",
      "       -0.01238325,  1.        ,  0.8602034 ,  0.99951106,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00820452, -0.05915803,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.36674118, -0.30254197,  0.06298232,  0.        ,  0.4395175 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.4781487 ,  0.28011537,\n",
      "        0.71878576,  0.        ,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.44440925,  0.5452019 ,  0.15506536,\n",
      "        0.74911153,  0.20060621, -0.31483287,  0.7833124 , -0.4416376 ,\n",
      "        0.24532327, -0.45721418,  0.07464848, -0.40266523,  0.12688814,\n",
      "       -0.33844304,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00387484, -0.05626065,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.9167893 , -0.37120032,  0.9847739 ,  0.        ,  0.7800844 ,\n",
      "        0.15279603,  0.07578206,  0.        ,  0.        ,  0.        ,\n",
      "        0.6366372 ,  0.6855335 ,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.44457832,  0.26033103,  0.18565808,\n",
      "        0.45329732,  0.18192181, -0.56917095,  0.783162  , -0.72601575,\n",
      "        0.21728355, -0.7359276 ,  0.1160595 , -0.70014614,  0.09057598,\n",
      "       -0.58959   ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00402483, -0.05620846,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.13162303,  0.6850085 ,  0.9807937 ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.93203306,  0.        ,  0.50433564,\n",
      "        0.        ,  0.        ,  0.92834663,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.45381212,  0.37395692,  0.15858102,\n",
      "        0.5325786 ,  0.15497158, -0.42254362,  0.77492553, -0.59597576,\n",
      "        0.22340426, -0.5864903 ,  0.13026364, -0.5458347 ,  0.0420119 ,\n",
      "       -0.3619956 ,  1.        ,  0.77573675,  0.8120529 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00894147, -0.05335152,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.9783933 , 0.4344182 , 0.4275124 , 0.85502934, 0.        ,\n",
      "       0.        , 0.21390533, 0.        , 0.        , 0.        ,\n",
      "       0.8736131 , 0.        , 0.        , 0.6985557 , 0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.45006767,  0.57983917,  0.19470522,\n",
      "        0.78370076,  0.10609355, -0.4044358 ,  0.7782366 , -0.44455275,\n",
      "        0.23696017, -0.48119974,  0.1744953 , -0.5258894 ,  0.04257824,\n",
      "       -0.5806279 ,  1.        ,  0.56437457,  0.9996071 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00722286, -0.05450454,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.51542425,  0.2589829 , -0.2851975 ,  0.        ,  0.        ,\n",
      "        0.20114994,  0.7564268 ,  0.41090322,  0.9638579 ,  0.99105954,\n",
      "        0.9401238 ,  0.05442357,  0.        ,  0.57119656,  0.46282363],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.44841066,  0.3142766 ,  0.18772669,\n",
      "        0.5149983 ,  0.11436763, -0.6461056 ,  0.77952987, -0.70397604,\n",
      "        0.2803527 , -0.7433466 ,  0.20398363, -0.8159909 ,  0.03296497,\n",
      "       -0.78336644,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00540239, -0.05497825,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.90055203, -0.5352993 , -0.46989608,  0.        ,  0.15232325,\n",
      "        0.        ,  0.33307195,  0.        ,  0.        ,  0.        ,\n",
      "        0.70327926,  0.86457944,  0.        ,  0.9997041 ,  0.4204266 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.41019168,  0.17408417,  0.13551539,\n",
      "        0.40925175,  0.12194213, -0.93355715,  0.82155865, -0.8818197 ,\n",
      "        0.30638883, -0.94137067,  0.27102834,  0.9561835 ,  0.08342133,\n",
      "        0.97562695,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01585737, -0.06851432,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.3177626 , 0.11319971, 0.63708115, 0.        , 0.        ,\n",
      "       0.        , 0.00299335, 0.13908744, 0.        , 0.        ,\n",
      "       0.2502048 , 0.        , 0.2820866 , 0.87559867, 0.27002192],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.43573862,  0.06784488,  0.111853  ,\n",
      "        0.2202067 ,  0.07498562,  0.971478  ,  0.79474425, -0.9786012 ,\n",
      "        0.2779091 ,  0.95605624,  0.24258879,  0.8616118 ,  0.03698445,\n",
      "        0.66599286,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01357001, -0.05973184,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.13318706,  0.6138258 , -0.75329995,  0.        ,  0.52552485,\n",
      "        0.5769508 ,  0.18896961,  0.5652671 ,  0.        ,  0.5746448 ,\n",
      "        0.28049827,  0.8663087 ,  0.        ,  0.7706089 ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4769248 ,  0.2572903 ,  0.13602893,\n",
      "        0.30381617,  0.06999899, -0.8802946 ,  0.7513643 , -0.767178  ,\n",
      "        0.23096998, -0.8362035 ,  0.18686284,  0.9745699 ,  0.03451807,\n",
      "        0.47753814,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00741911, -0.04558021,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.0399282 ,  0.28730798,  0.34057856,  0.        ,  0.1644845 ,\n",
      "        0.        ,  0.72507524,  0.7987752 ,  0.        ,  0.        ,\n",
      "        0.        ,  0.6154125 ,  0.        ,  0.        ,  0.11393952],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.46457693,  0.22189358,  0.11317425,\n",
      "        0.20437518,  0.04672404, -0.8281912 ,  0.7647801 , -0.8147647 ,\n",
      "        0.23758072, -0.9230107 ,  0.20333067,  0.8887742 ,  0.03340705,\n",
      "        0.52117515,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01100269, -0.04990253,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.51221085,  0.23856664, -0.50352   ,  0.2787609 ,  0.        ,\n",
      "        0.        ,  0.        ,  0.9262521 ,  0.        ,  0.7980187 ,\n",
      "        0.        ,  0.16339612,  0.20921731,  0.88543034,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.47123563, -0.013903  ,  0.11079954,\n",
      "       -0.15315378,  0.08266542,  0.885164  ,  0.7579382 ,  0.9512509 ,\n",
      "        0.22983533,  0.7972815 ,  0.23188199,  0.6161584 ,  0.05152478,\n",
      "        0.31512028,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01052046, -0.04765123,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.5979371 , -0.14274526,  0.4737506 ,  0.24442148,  0.        ,\n",
      "        0.32755256,  0.        ,  0.        ,  0.7700541 ,  0.        ,\n",
      "        0.45419502,  0.        ,  0.        ,  0.9665518 ,  0.93641496],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.47329062, -0.12330992,  0.09470113,\n",
      "       -0.11502118,  0.05010223,  0.8024939 ,  0.75594765,  0.8411868 ,\n",
      "        0.22841169,  0.68538576,  0.23891851,  0.5030614 ,  0.05251184,\n",
      "        0.19432396,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01073149, -0.0469813 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.8059604 , -0.6147859 ,  0.6449995 ,  0.5721185 ,  0.09208822,\n",
      "        0.6853807 ,  0.        ,  0.7706022 ,  0.        ,  0.1663363 ,\n",
      "        0.99991417,  0.075212  ,  0.0553844 ,  0.        ,  0.4291253 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.49667543, -0.20534375,  0.12824403,\n",
      "       -0.07128622,  0.03760028,  0.5436547 ,  0.73464787,  0.7428078 ,\n",
      "        0.21869226,  0.55804783,  0.2445111 ,  0.376781  ,  0.0561639 ,\n",
      "       -0.11769945,  1.        ,  0.1665208 , -0.73366696,  0.        ,\n",
      "        0.8337541 ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01595324, -0.03962123,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.5532882 , -0.47948456,  0.27607632,  0.        ,  0.        ,\n",
      "        0.30263782,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.3076911 ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.47245476, -0.37983945,  0.09177614,\n",
      "       -0.25849798,  0.03443798,  0.59141576,  0.75526404,  0.60609144,\n",
      "        0.21904697,  0.4663999 ,  0.20482558,  0.28396016,  0.05387942,\n",
      "       -0.579305  ,  1.        ,  0.97721416,  0.03389755,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.004251  , -0.04694849,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.86774755, 0.63250685, 0.954412  , 0.43026233, 0.        ,\n",
      "       0.        , 0.98960066, 0.74223113, 0.83887815, 0.79742026,\n",
      "       0.5023515 , 0.09419751, 0.        , 0.8606212 , 0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.49548727, -0.17804982,  0.12006594,\n",
      "       -0.08141502,  0.03624786,  0.49759135,  0.7345509 ,  0.7794195 ,\n",
      "        0.21391098,  0.60161597,  0.2329957 ,  0.40963873,  0.06628621,\n",
      "       -0.22163293,  1.        , -0.83768034,  0.18967728,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01306903, -0.03976136,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.19372535,  0.8716912 , -0.332973  ,  0.        ,  0.        ,\n",
      "        0.7760761 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.35146403,  0.79274964,  0.14480782,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5208801 , -0.01008337,  0.14676006,\n",
      "        0.08201502,  0.06282101,  0.57889086,  0.7104159 ,  0.9384607 ,\n",
      "        0.20002024,  0.73072237,  0.22552015,  0.548042  ,  0.07584165,\n",
      "        0.04677852,  1.        , -0.67405665,  0.2946969 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01606173, -0.03155607,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.03984165,  0.14442301, -0.16596937,  0.8310003 ,  0.        ,\n",
      "        0.26522255,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.9626467 ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4838671 , -0.26471856,  0.10737412,\n",
      "       -0.24310672,  0.06652551,  0.5959944 ,  0.74464697,  0.7077623 ,\n",
      "        0.215309  ,  0.54987186,  0.21047017,  0.38247928,  0.03307988,\n",
      "       -0.20947772,  1.        , -0.91565126,  0.10822672,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00839075, -0.04331949,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.91799974, -0.83388305, -0.30972743,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.7783537 ,  0.        ,  0.01848626,  0.        ,  0.361732  ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4854457 , -0.5912943 ,  0.08023751,\n",
      "       -0.42628127,  0.09789499,  0.34465498,  0.7440779 ,  0.37054616,\n",
      "        0.2196247 ,  0.20390062,  0.21073146,  0.066744  ,  0.06707951,\n",
      "       -0.65453625,  1.        ,  0.75137526,  0.14872994,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01164785, -0.04299805,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.3568504 , -0.82653666,  0.02486157,  0.        ,  0.46971393,\n",
      "        0.        ,  0.        ,  0.81118846,  0.        ,  0.        ,\n",
      "        0.        ,  0.78500366,  0.        ,  0.        ,  0.73814535],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.48624328, -0.64773446,  0.04635655,\n",
      "       -0.27900547,  0.07665726,  0.24043944,  0.74305624,  0.3162109 ,\n",
      "        0.21781047,  0.15032092,  0.20012502, -0.00274691,  0.05075544,\n",
      "       -0.6284446 ,  1.        ,  0.69623196,  0.14374925,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01101652, -0.0426878 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.86125636, -0.8189006 ,  0.7268529 ,  0.        ,  0.        ,\n",
      "        0.09613156,  0.        ,  0.89689493,  0.7689438 ,  0.        ,\n",
      "        0.        ,  0.        ,  0.30267692,  0.79363656,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4930897 , -0.2988996 ,  0.09971622,\n",
      "        0.05335201,  0.09466629,  0.38154918,  0.745218  ,  0.6146926 ,\n",
      "        0.24513824,  0.4160977 ,  0.22960348,  0.2777613 ,  0.07222089,\n",
      "       -0.02770712,  1.        , -0.9852519 ,  0.3048498 ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02657899, -0.04221621,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.0417695 ,  0.91900706,  0.8517177 ,  0.        ,  0.36757684,\n",
      "        0.23835206,  0.        ,  0.        ,  0.        ,  0.7459178 ,\n",
      "        0.        ,  0.5957861 ,  0.        ,  0.5329673 ,  0.95574117],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.47621357,  0.01226076,  0.09190287,\n",
      "        0.5709988 ,  0.13919047,  0.73531634,  0.7598025 ,  0.93502325,\n",
      "        0.2528713 ,  0.7463169 ,  0.21231726,  0.6357553 ,  0.05654693,\n",
      "        0.33480954,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02344003, -0.04739609,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.8633456 , -0.02949119, -0.8273556 ,  0.        ,  0.        ,\n",
      "        0.82317424,  0.36045432,  0.        ,  0.42041826,  0.        ,\n",
      "        0.8664329 ,  0.        ,  0.        ,  0.        ,  0.74456835],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.42508763,  0.01499868,  0.13091546,\n",
      "        0.7406482 ,  0.18981515,  0.77758014,  0.81012404,  0.9400638 ,\n",
      "        0.28875554,  0.7798847 ,  0.20893373,  0.7297696 ,  0.07195075,\n",
      "        0.70081335,  1.        ,  0.96576947,  0.9880589 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02164683, -0.06430909,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.12594318,  0.5547416 ,  0.17132306,  0.        ,  0.40262556,\n",
      "        0.        ,  0.        ,  0.45864153,  0.8823819 ,  0.        ,\n",
      "        0.60863113,  0.57574654,  0.8139641 ,  0.1400733 ,  0.43084645],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.42686364, -0.33515263,  0.15881015,\n",
      "        0.3983262 ,  0.18929863,  0.42307362,  0.8086642 ,  0.5884632 ,\n",
      "        0.3236116 ,  0.45733446,  0.20432395,  0.37487036,  0.07184097,\n",
      "        0.33874667,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02211392, -0.06378496,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.05092311, -0.20947504,  0.80859137,  0.        ,  0.0449028 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.549762  ,\n",
      "        0.04423642,  0.        ,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.452115  , -0.29596534,  0.17156355,\n",
      "        0.37341762,  0.20441541,  0.36382687,  0.7963886 ,  0.58210933,\n",
      "        0.36515415,  0.4315086 ,  0.21669228,  0.3169447 ,  0.10713243,\n",
      "        0.07657845,  1.        ,  0.13797095, -0.7585752 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.0362846 , -0.05811962,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.23040938,  0.06082535, -0.8621423 ,  0.5741539 ,  0.11967206,\n",
      "        0.        ,  0.        ,  0.        ,  0.950042  ,  0.5119064 ,\n",
      "        0.3111031 ,  0.        ,  0.88230324,  0.7569721 ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4505962 , -0.40833402,  0.17068566,\n",
      "        0.27755257,  0.20326844,  0.26549885,  0.7966207 ,  0.47331563,\n",
      "        0.3860129 ,  0.32973292,  0.2116328 ,  0.2150564 ,  0.11609349,\n",
      "        0.03599559,  1.        ,  0.5158439 ,  0.97179663,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.03513053, -0.058355  ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.25732017, -0.744452  ,  0.6532371 ,  0.        ,  0.        ,\n",
      "        0.61846566,  0.898777  ,  0.        ,  0.33278227,  0.58010507,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.46201313, -0.7281762 ,  0.15235056,\n",
      "        0.00511729,  0.18797475, -0.01196163,  0.77356064,  0.19623585,\n",
      "        0.3532861 ,  0.07147933,  0.16628855, -0.06223926,  0.0685173 ,\n",
      "       -0.53010905,  1.        , -0.19831477, -0.8026681 ,  0.        ,\n",
      "        0.85542345,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02266246, -0.05205017,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.17311597,  0.37367725, -0.7553253 ,  0.06949997,  0.01101065,\n",
      "        0.        ,  0.03981447,  0.3363924 ,  0.        ,  0.73754644,\n",
      "        0.5711973 ,  0.48294044,  0.549037  ,  0.9137006 ,  0.98689055],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.45367602, -0.7451281 ,  0.1730216 ,\n",
      "        0.00222213,  0.20010106, -0.03317593,  0.78388804,  0.17027757,\n",
      "        0.3705036 ,  0.08948838,  0.17521232, -0.0777019 ,  0.06744926,\n",
      "       -0.5087471 ,  1.        ,  0.664021  ,  0.6884577 ,  0.        ,\n",
      "        0.805209  ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02517187, -0.05525732,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.5971265 , -0.90052104,  0.7730024 ,  0.        ,  0.7415638 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.3045125 ,  0.9232414 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.9245591 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4796264 , -0.7272163 ,  0.10334408,\n",
      "        0.01674546,  0.20249459, -0.00881235,  0.7520656 ,  0.21836732,\n",
      "        0.33490744,  0.14201203,  0.13303146, -0.04400133,  0.07942317,\n",
      "       -0.7150427 ,  1.        ,  0.12621157, -0.94144845,  0.        ,\n",
      "        0.8587572 ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01654479, -0.04537335,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.9579203 , 0.02690959, 0.22565842, 0.        , 0.5818403 ,\n",
      "       0.        , 0.8547313 , 0.        , 0.7241769 , 0.        ,\n",
      "       0.6987388 , 0.        , 0.9016993 , 0.2758267 , 0.61790514],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.47213915, -0.86644924,  0.10754119,\n",
      "       -0.14169523,  0.19472717, -0.16129623,  0.7603769 ,  0.07398628,\n",
      "        0.39241496,  0.00240476,  0.139555  , -0.16772568,  0.08457601,\n",
      "        0.9749012 ,  1.        , -0.9032382 ,  0.99744165,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01800042, -0.04803663,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.9558215 , -0.5688839 ,  0.30147672,  0.39125633,  0.        ,\n",
      "        0.        ,  0.599875  ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.0702877 ,  0.64773154,  0.        ,  0.88437676],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4573641 , -0.50641143,  0.15854426,\n",
      "        0.2889642 ,  0.24813145,  0.22993365,  0.7786935 ,  0.41560796,\n",
      "        0.43888012,  0.33413565,  0.1623243 ,  0.19398022,  0.04449932,\n",
      "       -0.42390433,  1.        , -0.7358036 , -0.5572073 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.02326834, -0.05370545,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.99164176,  0.12525868, -0.05211139,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.10515928,  0.8444402 ,  0.        ,\n",
      "        0.23251271,  0.        ,  0.01477647,  0.58938384,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4695999 , -0.6349954 ,  0.1264581 ,\n",
      "        0.28407064,  0.22816849,  0.19743474,  0.75865626,  0.34110054,\n",
      "        0.4095281 ,  0.2487761 ,  0.11945605,  0.17334932,  0.11366142,\n",
      "       -0.73995686,  1.        , -0.3391044 ,  0.2725944 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00720927, -0.04800656,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.28449845, -0.7037182 ,  0.8403628 ,  0.        ,  0.41280437,\n",
      "        0.        ,  0.9113426 ,  0.5042093 ,  0.        ,  0.76025033,\n",
      "        0.        ,  0.07827044,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4631144 , -0.58577883,  0.17817426,\n",
      "        0.25687283,  0.28580463,  0.25440383,  0.7670683 ,  0.3703604 ,\n",
      "        0.4164736 ,  0.26035717,  0.13525027,  0.17139907,  0.0780666 ,\n",
      "       -0.73937076,  1.        , -0.36241108,  0.3762494 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.01315403, -0.05055994,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.29906678, -0.5492773 ,  0.08636379,  0.        ,  0.52344704,\n",
      "        0.91136   ,  0.69630504,  0.40222907,  0.81011796,  0.        ,\n",
      "        0.19208932,  0.        ,  0.45917845,  0.        ,  0.38736415],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.4839271 , -0.6663277 ,  0.16902182,\n",
      "        0.2550897 ,  0.28700718,  0.2782214 ,  0.7436056 ,  0.3425016 ,\n",
      "        0.35551393,  0.2293457 ,  0.09294738,  0.22254305,  0.13278833,\n",
      "       -0.8261112 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00269234, -0.04310209,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.34922075, -0.8336246 , -0.18415809,  0.39758396,  0.7124934 ,\n",
      "        0.80337596,  0.16061115,  0.24785328,  0.        ,  0.        ,\n",
      "        0.6999142 ,  0.94948506,  0.        ,  0.1731906 ,  0.6639612 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.48345357, -0.3877459 ,  0.1748186 ,\n",
      "        0.49721065,  0.27390155,  0.52711624,  0.74404156,  0.60507   ,\n",
      "        0.36710122,  0.48611745,  0.10234907,  0.4620504 ,  0.17196913,\n",
      "       -0.49910057,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00218877, -0.04325172,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.05612111,  0.5957618 , -0.17001343,  0.04414177,  0.6203265 ,\n",
      "        0.        ,  0.        ,  0.635977  ,  0.06451726,  0.62069726,\n",
      "        0.        ,  0.6397166 ,  0.        ,  0.65657926,  0.5383444 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.49014366, -0.15847257,  0.21346404,\n",
      "        0.7007459 ,  0.3188502 ,  0.75713205,  0.7375943 ,  0.8265339 ,\n",
      "        0.327915  ,  0.69937164,  0.10360871,  0.66940284,  0.20136371,\n",
      "       -0.2437087 ,  1.        ,  0.83251506,  0.9995996 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00458771, -0.04107934,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.5526271 , -0.5024681 ,  0.5664189 ,  0.        ,  0.        ,\n",
      "        0.19369626,  0.89278483,  0.        ,  0.        ,  0.7913296 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.23417544],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.50794   ,  0.15923694,  0.2227748 ,\n",
      "       -0.97070783,  0.32872295, -0.91754717,  0.7197448 , -0.85488814,\n",
      "        0.2649624 , -0.9863216 ,  0.09211191,  0.9706075 ,  0.24322109,\n",
      "        0.13284642,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00437117, -0.03516024,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.9230499 , -0.09665298, -0.9080627 ,  0.        ,  0.52062917,\n",
      "        0.        ,  0.3870201 ,  0.11709046,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.37093568,  0.1475339 ,  0.23674774],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.51085097, -0.06850372,  0.25584912,\n",
      "        0.8188798 ,  0.29850337,  0.8470565 ,  0.71682125,  0.91762465,\n",
      "        0.22149383,  0.7615145 ,  0.08563238,  0.72491306,  0.25519726,\n",
      "       -0.06341751,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00430122, -0.03419134,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.46108508, -0.7881825 ,  0.34298992,  0.614156  ,  0.26444077,\n",
      "        0.8170934 ,  0.        ,  0.        ,  0.7464199 ,  0.20081091,\n",
      "        0.        ,  0.08605433,  0.43732476,  0.        ,  0.7519698 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.48211184,  0.12578662,  0.24350362,\n",
      "       -0.99540085,  0.36020416, -0.9485612 ,  0.7457389 , -0.8914593 ,\n",
      "        0.19917704,  0.96944153,  0.10723818,  0.9500658 ,  0.22598772,\n",
      "        0.13214128,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00524729, -0.04376882,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.5670383 , -0.07448316,  0.00161219,  0.7716708 ,  0.        ,\n",
      "        0.6443963 ,  0.        ,  0.        ,  0.43643594,  0.        ,\n",
      "        0.        ,  0.52018166,  0.8753798 ,  0.        ,  0.13705826],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.52655447,  0.14946844,  0.19072653,\n",
      "       -0.958138  ,  0.35180986, -0.89315116,  0.7008559 , -0.8456861 ,\n",
      "        0.10291027,  0.98955953,  0.05360987,  0.94943786,  0.27269697,\n",
      "        0.08170799,  1.        ,  0.65982676,  0.24285433,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.0015142 , -0.0289281 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.9355216 ,  0.42294407, -0.80014205,  0.        ,  0.        ,\n",
      "        0.        ,  0.10399199,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.5356443 ,  0.14464235,  0.10240388,  0.31409693],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5396734 ,  0.43869215,  0.19365649,\n",
      "       -0.60047114,  0.30039752, -0.57089067,  0.6886966 , -0.5353208 ,\n",
      "        0.06724051, -0.71085525,  0.03530626, -0.66338104,  0.28988615,\n",
      "        0.36427063,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00816724, -0.02475211,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.17206454,  0.45145893, -0.2725463 ,  0.        ,  0.        ,\n",
      "        0.99285245,  0.        ,  0.        ,  0.        ,  0.44354463,\n",
      "        0.        ,  0.        ,  0.84742475,  0.        ,  0.6477053 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5362319 ,  0.48498222,  0.2292056 ,\n",
      "       -0.562456  ,  0.32281747, -0.57049096,  0.69118565, -0.52077603,\n",
      "        0.08646496, -0.8472206 ,  0.05616548, -0.7810717 ,  0.27734175,\n",
      "        0.4048497 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.0018068 , -0.0257172 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.6058905 , -0.49510002,  0.39680433,  0.37839508,  0.18131137,\n",
      "        0.        ,  0.0497601 ,  0.4463017 ,  0.15646744,  0.28882742,\n",
      "        0.43564272,  0.        ,  0.9611926 ,  0.        ,  0.87346864],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5468386 ,  0.2966656 ,  0.2123486 ,\n",
      "       -0.636343  ,  0.25873226, -0.703209  ,  0.68320256, -0.66101485,\n",
      "        0.03281332,  0.96899134,  0.03388737, -0.6561994 ,  0.30372012,\n",
      "        0.20300457,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01336372, -0.02268028,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.56726694, -0.3364575 ,  0.88295794,  0.7495048 ,  0.        ,\n",
      "        0.2894497 ,  0.        ,  0.        ,  0.8052385 ,  0.        ,\n",
      "        0.98476624,  0.47344375,  0.        ,  0.97153115,  0.72149515],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5395369 ,  0.12736015,  0.25106683,\n",
      "       -0.83210886,  0.21800809, -0.8684163 ,  0.68979365, -0.8363123 ,\n",
      "        0.04792555,  0.84575313,  0.0459777 , -0.88890994,  0.30303875,\n",
      "        0.04521699,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01142493, -0.02497652,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.610389  ,  0.06519341, -0.9460921 ,  0.93960285,  0.4949193 ,\n",
      "        0.07179928,  0.81361294,  0.2085917 ,  0.17053151,  0.        ,\n",
      "        0.        ,  0.10353255,  0.74530816,  0.6161928 ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5163812 ,  0.32964367,  0.24989906,\n",
      "       -0.67868406,  0.29358545, -0.7122661 ,  0.7112305 , -0.65794   ,\n",
      "        0.04104079, -0.86192054,  0.07877506, -0.7852696 ,  0.2644338 ,\n",
      "        0.28167045,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00386438, -0.03234366,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.57991767, -0.69776225,  0.93318534,  0.        ,  0.64152217,\n",
      "        0.        ,  0.1887691 ,  0.5972643 ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.3633237 ,  0.646785  ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5080958 ,  0.4761552 ,  0.2481134 ,\n",
      "       -0.58858556,  0.30758417, -0.6119838 ,  0.7197925 , -0.5422492 ,\n",
      "        0.06735364, -0.799835  ,  0.10535014, -0.72775495,  0.23169056,\n",
      "        0.469442  ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00569376, -0.03514811,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.36597347, -0.6719003 , -0.12780142,  0.        ,  0.5547819 ,\n",
      "        0.3738408 ,  0.5709715 ,  0.        ,  0.4089241 ,  0.41121745,\n",
      "        0.        ,  0.        ,  0.20106721,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5129673 ,  0.43111518,  0.19037476,\n",
      "       -0.57116765,  0.27850783, -0.61671585,  0.71479684, -0.55287224,\n",
      "        0.04607085, -0.42050594,  0.08101558, -0.66043663,  0.23841909,\n",
      "        0.40134665,  1.        ,  0.01440976, -0.20289198,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00496814, -0.03350648,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.81206274,  0.12535286, -0.8737476 ,  0.5889089 ,  0.23654723,\n",
      "        0.        ,  0.        ,  0.        ,  0.2549007 ,  0.54785633,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.98184013],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.52133495,  0.7154691 ,  0.14229162,\n",
      "       -0.35717627,  0.28076565, -0.37025505,  0.7063652 , -0.2992494 ,\n",
      "        0.03820723, -0.42936003,  0.06959075, -0.5179814 ,  0.2347783 ,\n",
      "        0.70975226,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00459221, -0.03071597,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.6387272 ,  0.14434457,  0.46368718,  0.        ,  0.        ,\n",
      "        0.        ,  0.4652636 ,  0.        ,  0.        ,  0.03085399,\n",
      "        0.        ,  0.14993119,  0.        ,  0.11917377,  0.21839786],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.50424427,  0.9670103 ,  0.14324787,\n",
      "       -0.06175853,  0.2985756 , -0.13310137,  0.7231995 , -0.03867723,\n",
      "        0.04899831,  0.01694232,  0.10397716, -0.13734056,  0.22963911,\n",
      "        0.9506293 ,  1.        ,  0.5363372 ,  0.06081864,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00175694, -0.03634009,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.6857989 , -0.57801104, -0.65042853,  0.        ,  0.        ,\n",
      "        0.        ,  0.30924392,  0.35883164,  0.        ,  0.2875011 ,\n",
      "        0.        ,  0.        ,  0.21355367,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.46190467,  0.9135373 ,  0.15363929,\n",
      "       -0.03961252,  0.33719975, -0.1613814 ,  0.7655648 , -0.08286989,\n",
      "        0.09110451, -0.00321095,  0.1411043 , -0.10852377,  0.16664678,\n",
      "        0.8737205 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00107569, -0.05039966,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.3337896 , -0.5316925 , -0.7807894 ,  0.        ,  0.        ,\n",
      "        0.9700494 ,  0.859715  ,  0.        ,  0.7100775 ,  0.1910832 ,\n",
      "        0.        ,  0.97108245,  0.06576443,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.00000000e+00,  1.00000000e+00,  4.68312442e-01,  9.88112807e-01,\n",
      "        1.35318354e-01,  4.24236692e-02,  3.50613058e-01, -1.13210194e-01,\n",
      "        7.59141743e-01, -8.90368223e-03,  8.47575292e-02,  7.51002058e-02,\n",
      "        1.46695673e-01, -3.00044138e-02,  1.56531826e-01,  9.36199307e-01,\n",
      "        1.00000000e+00,  9.89959240e-01,  9.99993563e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        8.98689381e-04, -4.82694805e-02,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.27173638, -0.61709857, -0.05743361,  0.72293544,  0.        ,\n",
      "        0.        ,  0.5212991 ,  0.9567206 ,  0.        ,  0.        ,\n",
      "        0.02500153,  0.        ,  0.22014594,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5020409 , -0.7989585 ,  0.07199917,\n",
      "        0.26285064,  0.292973  ,  0.13587375,  0.7257524 ,  0.21748042,\n",
      "        0.05952448,  0.41083458,  0.08468849,  0.13015388,  0.19186617,\n",
      "       -0.8542432 ,  1.        ,  0.852129  , -0.18352346,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00507015, -0.03714007,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.6435616 , -0.58825946, -0.33663177,  0.60656285,  0.        ,\n",
      "        0.        ,  0.5870199 ,  0.        ,  0.        ,  0.2890854 ,\n",
      "        0.        ,  0.495847  ,  0.        ,  0.31991577,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5118305 , -0.6050608 ,  0.03110283,\n",
      "        0.656951  ,  0.23027894,  0.35720867,  0.7170895 ,  0.42722172,\n",
      "        0.06364815,  0.708521  ,  0.07711039,  0.44083148,  0.18150257,\n",
      "       -0.67614377,  1.        , -0.94478524, -0.4632125 ,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.21532637,  0.        ,  0.01001754, -0.03410789,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.39799237, -0.31433606, -0.9233434 ,  0.6041517 ,  0.        ,\n",
      "        0.36545348,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.5081587 ,  0.95394254,  0.6551161 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.06173753,\n",
      "        0.72111195,  0.18171114,  0.20373258,  0.71806055,  0.2648214 ,\n",
      "        0.06665745,  0.5505117 ,  0.06862564,  0.39220414,  0.13559584,\n",
      "       -0.87898326,  1.        ,  0.891399  , -0.47924373,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.14311337,  0.20890307, -0.10226417,  0.4207008 ,  0.        ,\n",
      "        0.        ,  0.3122046 ,  0.        ,  0.03462434,  0.02648115,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.3334601 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.07560127,\n",
      "        0.7265719 ,  0.17105862,  0.20918714,  0.71806055,  0.2648214 ,\n",
      "        0.06665745,  0.5505117 ,  0.06990156,  0.37835655,  0.09011246,\n",
      "       -0.9531067 ,  1.        ,  0.891399  , -0.47924373,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.05483675, -0.45632434,  0.35329628,  0.        ,  0.        ,\n",
      "        0.39911628,  0.6072302 ,  0.        ,  0.6712506 ,  0.8812835 ,\n",
      "        0.        ,  0.05184388,  0.        ,  0.        ,  0.9410467 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.1141059 ,\n",
      "        0.7016582 ,  0.15282412,  0.25058544,  0.71806055,  0.2648214 ,\n",
      "        0.06665745,  0.5505117 ,  0.09381243,  0.4635262 ,  0.07324421,\n",
      "        0.943022  ,  1.        ,  0.891399  , -0.47924373,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.571692  , -0.42491484, -0.6409917 ,  0.58555365,  0.59810424,\n",
      "        0.62112236,  0.37819958,  0.        ,  0.        ,  0.823632  ,\n",
      "        0.58696294,  0.995867  ,  0.80711555,  0.5195701 ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.09974046,\n",
      "        0.6945739 ,  0.13913757,  0.29718098,  0.71806055,  0.2648214 ,\n",
      "        0.06665745,  0.5505117 ,  0.09347448,  0.35907   ,  0.06830131,\n",
      "        0.88956153,  1.        ,  0.891399  , -0.47924373,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.17723465, -0.92115474,  0.7067442 ,  0.        ,  0.        ,\n",
      "        0.24862432,  0.06148839,  0.29861808,  0.74479294,  0.        ,\n",
      "        0.9377632 ,  0.58640003,  0.4463408 ,  0.9666395 ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.0948274 ,\n",
      "        0.69104946,  0.11034833,  0.33392182,  0.71806055,  0.2648214 ,\n",
      "        0.06665747,  0.5505124 ,  0.08024143,  0.41697267,  0.06830131,\n",
      "        0.88956153,  1.        ,  0.891399  , -0.47924536,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.34768558, -0.94200444,  0.431715  ,  0.66928124,  0.57735133,\n",
      "        0.38099265,  0.        ,  0.        ,  0.        ,  0.11715317,\n",
      "        0.        ,  0.6079099 ,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.11364178,\n",
      "        0.6955912 ,  0.08405872,  0.30063462,  0.71806055,  0.2648214 ,\n",
      "        0.06665747,  0.5505124 ,  0.04582162,  0.3842506 ,  0.07676835,\n",
      "        0.92211634,  1.        ,  0.891399  , -0.47924536,  0.        ,\n",
      "        0.8006251 ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.7123468 ,  0.69348836,  0.75240993,  0.9303539 ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.47287226,  0.38497305,\n",
      "        0.        ,  0.04504085,  0.        ,  0.        ,  0.13469553],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.0913282 ,\n",
      "        0.6897672 ,  0.0562275 ,  0.24008827,  0.71806055,  0.2648214 ,\n",
      "        0.07039054,  0.4302352 ,  0.03381059,  0.4377191 ,  0.07757545,\n",
      "        0.9280978 ,  1.        , -0.7373048 ,  0.997478  ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.9079356 , -0.19265461,  0.35268402,  0.        ,  0.        ,\n",
      "        0.6426096 ,  0.        ,  0.        ,  0.        ,  0.11188579,\n",
      "        0.07508302,  0.        ,  0.        ,  0.07773042,  0.35483336],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.1352561 ,\n",
      "        0.63500553,  0.03381031,  0.1108723 ,  0.71806055,  0.2648214 ,\n",
      "        0.07018312,  0.37280658,  0.03369363,  0.43990523,  0.09602838,\n",
      "        0.7730024 ,  1.        , -0.74997765,  0.99891883,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.5644238 , -0.11554646,  0.6871629 ,  0.        ,  0.47223258,\n",
      "        0.4468677 ,  0.1653831 ,  0.        ,  0.        ,  0.        ,\n",
      "        0.1577034 ,  0.37292004,  0.23882055,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.13974033,\n",
      "        0.59734255,  0.03333333,  0.11839632,  0.71806055,  0.2648214 ,\n",
      "        0.0893338 ,  0.41526425,  0.03351174,  0.8698845 ,  0.13881795,\n",
      "        0.69914204,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.99316764,  0.4208188 , -0.4906311 ,  0.1119051 ,  0.3742745 ,\n",
      "        0.        ,  0.        ,  0.        ,  0.8020849 ,  0.82895947,\n",
      "        0.29045272,  0.        ,  0.8827331 ,  0.19164085,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.13197263,\n",
      "        0.656651  ,  0.03333332,  0.18069477,  0.71806055,  0.2648214 ,\n",
      "        0.13191144,  0.37970236,  0.03333339, -0.8729498 ,  0.1054893 ,\n",
      "        0.7251196 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([-0.96780133, -0.48546934, -0.81846786,  0.38455915,  0.        ,\n",
      "        0.53182554,  0.21405625,  0.        ,  0.        ,  0.        ,\n",
      "        0.48587132,  0.        ,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.12691994,\n",
      "        0.65478444,  0.04631075,  0.51470923,  0.71806055,  0.2648214 ,\n",
      "        0.16795085,  0.35905012,  0.05315066,  0.8427142 ,  0.1054893 ,\n",
      "        0.7251196 ,  1.        , -0.74997765,  0.99891883,  0.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.8523371 , -0.14275074, -0.8091154 ,  0.        ,  0.1440196 ,\n",
      "        0.7448461 ,  0.67151475,  0.72485113,  0.56435585,  0.42678285,\n",
      "        0.        ,  0.        ,  0.4160986 ,  0.        ,  0.61078095],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.1507128 ,\n",
      "        0.6623046 ,  0.05038501,  0.55265176,  0.71806055,  0.2648214 ,\n",
      "        0.17401238,  0.349623  ,  0.07225633,  0.73163635,  0.11996235,\n",
      "        0.7034914 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.5668869 , 0.697474  , 0.61547804, 0.20089936, 0.06004357,\n",
      "       0.        , 0.        , 0.5030303 , 0.        , 0.        ,\n",
      "       0.        , 0.94252753, 0.        , 0.68116   , 0.13394642],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.16544564,\n",
      "        0.70433575,  0.06454068,  0.7577562 ,  0.71806055,  0.2648214 ,\n",
      "        0.18000247,  0.43225196,  0.07441188,  0.9338248 ,  0.13303202,\n",
      "        0.6761546 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([0.93923426, 0.18034124, 0.2868278 , 0.19678187, 0.        ,\n",
      "       0.10926652, 0.        , 0.26507187, 0.        , 0.        ,\n",
      "       0.        , 0.87874746, 0.        , 0.7692468 , 0.9678936 ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.16329688,\n",
      "        0.80547106,  0.0502757 ,  0.9411208 ,  0.71806055,  0.2648214 ,\n",
      "        0.18613318,  0.35674632,  0.11109691, -0.9316733 ,  0.16258271,\n",
      "        0.697601  ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "<class 'numpy.ndarray'>\n",
      "Trajectory(\n",
      "{'action': array([ 0.52296877, -0.78147364, -0.8381667 ,  0.        ,  0.        ,\n",
      "        0.        ,  0.7150161 ,  0.        ,  0.93878365,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
      "      dtype=float32),\n",
      " 'discount': array(1., dtype=float32),\n",
      " 'next_step_type': array(1, dtype=int32),\n",
      " 'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.15555882,\n",
      "        0.8431791 ,  0.04869492,  0.97488964,  0.71806055,  0.2648214 ,\n",
      "        0.15863504,  0.3811775 ,  0.10602856, -0.9871982 ,  0.14971848,\n",
      "        0.6877354 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
      " 'policy_info': (),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'discount': array(1., dtype=float32),\n",
       "  'observation': array([ 1.        ,  1.        ,  0.5111935 , -0.7707966 ,  0.15485238,\n",
       "         0.9167367 ,  0.06586765,  0.720049  ,  0.71806055,  0.2648214 ,\n",
       "         0.1638141 ,  0.372696  ,  0.11164905, -0.8985493 ,  0.164289  ,\n",
       "         0.67954135,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.01105312, -0.03438446,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ], dtype=float32),\n",
       "  'reward': array(0., dtype=float32),\n",
       "  'step_type': array(1, dtype=int32)}),\n",
       " ())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      random_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=initial_collect_steps).run(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MakeIterator_device_/job:localhost/replica:0/task:0/device:CPU:0}} Requested incompatible tensor at flattened index 0 from table 'test_table'.  Requested (dtype, shape): (int32, [1]).  Signature (dtype, shape): (int32, []).  Table signature: 0: Tensor<name: 'step_type/step_type', dtype: int32, shape: []>, 1: Tensor<name: 'observation/observation', dtype: float, shape: [64]>, 2: Tensor<name: 'action/action', dtype: float, shape: [15]>, 3: Tensor<name: 'policy_info/dist_params/loc/NormalProjectionNetwork_loc', dtype: float, shape: [15]>, 4: Tensor<name: 'policy_info/dist_params/scale/NormalProjectionNetwork_scale', dtype: float, shape: [15]>, 5: Tensor<name: 'next_step_type/step_type', dtype: int32, shape: []>, 6: Tensor<name: 'reward/reward', dtype: float, shape: []>, 7: Tensor<name: 'discount/discount', dtype: float, shape: []> [Op:MakeIterator]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/trist/code/Biny17/derks-gym/ppo_agent2.ipynb Cell 11\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/trist/code/Biny17/derks-gym/ppo_agent2.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39miter\u001b[39;49m(replay_buffer\u001b[39m.\u001b[39;49mas_dataset())\u001b[39m.\u001b[39mnext()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:4177\u001b[0m, in \u001b[0;36mDatasetV1Adapter.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> 4177\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:505\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[1;32m    504\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    506\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:713\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    709\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    710\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    711\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    712\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 713\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[1;32m    715\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:752\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    749\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(fulltype\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[1;32m    750\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_types)\n\u001b[1;32m    751\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 752\u001b[0m gen_dataset_ops\u001b[39m.\u001b[39;49mmake_iterator(ds_variant, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3412\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3410\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3411\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3412\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3413\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3414\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MakeIterator_device_/job:localhost/replica:0/task:0/device:CPU:0}} Requested incompatible tensor at flattened index 0 from table 'test_table'.  Requested (dtype, shape): (int32, [1]).  Signature (dtype, shape): (int32, []).  Table signature: 0: Tensor<name: 'step_type/step_type', dtype: int32, shape: []>, 1: Tensor<name: 'observation/observation', dtype: float, shape: [64]>, 2: Tensor<name: 'action/action', dtype: float, shape: [15]>, 3: Tensor<name: 'policy_info/dist_params/loc/NormalProjectionNetwork_loc', dtype: float, shape: [15]>, 4: Tensor<name: 'policy_info/dist_params/scale/NormalProjectionNetwork_scale', dtype: float, shape: [15]>, 5: Tensor<name: 'next_step_type/step_type', dtype: int32, shape: []>, 6: Tensor<name: 'reward/reward', dtype: float, shape: []>, 7: Tensor<name: 'discount/discount', dtype: float, shape: []> [Op:MakeIterator]"
     ]
    }
   ],
   "source": [
    "iter(replay_buffer.as_dataset()).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
